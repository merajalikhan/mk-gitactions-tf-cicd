name: 'Build Databricks Workflow'

on: 
  pull_request:
     branches: [ "main" ]
  
permissions:
  contents: read

   
env: 
  TF_VAR_databricks_host: ${{ secrets.DATABRICKS_HOST }}
  TF_VAR_databricks_token: ${{ secrets.DATABRICKS_TOKEN }}
  TF_WORKSPACE: ${{vars.TF_WORKSPACE}} #"mk-test-api-ws-api"  

jobs:  
  build-and-test:
    name: 'Build and Test'
    runs-on: ubuntu-latest
    environment:  ${{vars.GIT_ENVIRONMENT}}

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash
        working-directory: ./Terraform
    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout repository
      uses: actions/checkout@v3       
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

    - name: Init Terraform
      run: |                                       
        terraform init   

    - name: Unit tests    
            
      uses: databricks/run-notebook@v0
      with:
          local-notebook-path: ./Terraform/Notebooks/MK-TEST-20230518.py
          databricks-host: ${{ secrets.DATABRICKS_HOST }}
          databricks-token: ${{ secrets.DATABRICKS_TOKEN }}
          git-commit: ${{ github.event.pull_request.head.sha }}
          new-cluster-json: >
            {
              "num_workers": 1,
              "spark_version": "12.2.x-scala2.12", 
              "node_type_id": "Standard_DS3_v2"
            }  
          access-control-list-json: >
            [
              {
                "group_name": "users",
                "permission_level": "CAN_VIEW"
              }
            ] 

    - name: Archive artifacts
      uses: actions/upload-artifact@v3
      with:
        name: tf-files
        path: |
          Terraform
          !.terraform
          retention-days: 2
      




       




    
         
      
      
      
      
